<!--
#   VRxAR Labs | ODXVRxNTS 360 Viewer - Hashtag scenario
#
#   Author: Nico Reski
#   Email: nico.reski@lnu.se
#   Web: https://vrxar.lnu.se/apps/odxvrxnts-360/hashtag.html
#
#   Pannellum version: 2.4.0
-->

<!DOCTYPE HTML>

<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ODXVRxNTS: 360 Viewer - VRxAR Labs</title>
    <link rel="stylesheet" href="lib/pannellum.css"/>
    <script type="text/javascript" src="lib/pannellum.js" charset="utf-8"></script>

    <style type="text/css">
        #panorama {
            width:  100%;
            height: 500px;
        }

        /* Panorama element size adjustment based on device's screen size. */
        @media not screen and (max-width: 1024px) {
            #panorama {
                height: 576px;
            }
        }

        @media not screen and (max-width: 1280px) {
            #panorama {
                height: 720px;
            }
        }

        @media not screen and (max-width: 1600px) {
            #panorama {
                height: 900px;
            }
        }

        @media not screen and (max-width: 1920px) {
            #panorama {
                height: 1080px;
            }
        }
    </style>
</head>

<body>
    <div id="panorama"></div>

    <script>

        // determine which image to load via url parameter
        //

        var appURLString = window.location.href;        // grab url that was used to open this web app
        var appURL = new URL(appURLString);             // create URL object
        var ino = appURL.searchParams.get("ino");       // extract url argument "ino" (= image number)
        var imageFilePath = "";                         // string to store file path of loaded image
        switch(ino)
        {
            case "1":
            default:
                imageFilePath = "images/2019-05-03_ODXVRxNTS_Hashtag_360.jpg";
                break;
            case "2":
                imageFilePath = "images/2019-10-09_CHIIR_content.jpg";
                break;
            case "3":
                imageFilePath = "images/2019-10-09_CHIIR_bookmark.jpg";
                break;
        }


        // prepare hotspot data
        //
        
        var hotspotData = null;                                 // variable potentially holding hotspot data
        
        var annotated = appURL.searchParams.get("annot");       // extract url argument "annot" (= annotation)
        if (annotated != "false")
        {
            imageFilePath = "images/2019-05-03_ODXVRxNTS_Hashtag_360.jpg";

            // hotspot data for file: images/2019-01-25_ODXVRxNTS_360_07.jpg
            hotspotData = [
                {
                    "pitch": -31.0,
                    "yaw": 0.0,
                    "type": "info",
                    "text": "3D gestural input: The hands of the VR user are detected, then displayed, and translated into the virtual 3D space accordingly, live and in real-time, enabling interaction using hand postures and gestures."
                },
                {
                    "pitch": -37.0,
                    "yaw": -20.0,
                    "type": "info",
                    "text": "Interaction Pause Menu: Attached to the VR user's right-hand palm is a menu with one button, allowing the user to turn off/on the possibility to interact with the data in the immersive environment. This is helpful when the user wants to take a step back to simply observe the data or talk to a peer while gesturing and pointing without the intend to interact with the system itself."
                },
                {
                    "pitch": 6.0,
                    "yaw": -40.0,
                    "type": "info",
                    "text": "Information Panel - Center: Display a preview of the most frequent hashtags used within the tweets in the currently selected cluster. The preview is formatted as a tag cloud. The color of the hashtag indicates the language of the tweet it was detected in."
                },
                {
                    "pitch": 6.0,
                    "yaw": -80.0,
                    "type": "info",
                    "text": "Information Panel - Left: Display additional information about the currently selected cluster, for instance the total amount of tweets, the time of the presented data, as well as all unique location names that are contained within the currently selected cluster."
                },
                {
                    "pitch": 6.0,
                    "yaw": -2.0,
                    "type": "info",
                    "text": "Information Panel - Right: Display the detailed language distribution of the selected cluster (language name and its assigned color, share in percentage, amount of tweets)."
                },
                {
                    "pitch": -33.0,
                    "yaw": -37.0,
                    "type": "info",
                    "text": "Selected cluster: The cluster selected by the VR user is outlined with a red wire frame, while all other clusters feature a black wire frame."
                },
                {
                    "pitch": -11.0,
                    "yaw": 42.0,
                    "type": "info",
                    "text": "Cluster: A cluster represents all Twitter traffic within a radius of 60 km as 'stacked cuboids'. Each stacked cuboid consists of four parts: the size of the top three stacks of the cuboid represent, in order, the three most frequent languages detected within the cluster, while the size of the fourth stack represents the sum of all remaining tweets in other languages than the top three."
                },
                {
                    "pitch": -22.0,
                    "yaw": -106.0,
                    "type": "info",
                    "text": "Elevated cluster: Clusters in close proximity will get raised up approximately to the VR user's chest height to facilitate interaction under consideration of human factors and ergonomics. The cluster's shadow is projected to the virtual floor in order to keep a visual indication of its exact location."
                },
                {
                    "pitch": -18.0,
                    "yaw": 34.0,
                    "type": "info",
                    "text": "Nordic countries: The five Nordic countries (Denmark, Finland, Iceland, Norway, Sweden) are displayed, color-coded, on the floor within the virtual three-dimensional (3D) space."
                },
                {
                    "pitch": -12.0,
                    "yaw": 57.0,
                    "type": "info",
                    "text": "Cluster height: Each stacked cuboid's height is scaled according to the total amount of tweets within that cluster (the more tweets, the higher the cuboid, using a logarithmic scale)."
                }
            ];
        } 

        // load 360 image
        //

        // determine whether the page is viewn in portrait (typical for mobile) or landscape (typical for desktop) mode
        // and adjust field of view accordingly
        var computedHFOV = (screen.width > screen.height) ? 110 : 40;

        // create 360 viewer and load image
        pannellum.viewer('panorama', {
            "type": "equirectangular",
            "panorama": imageFilePath,
            "autoLoad": true,
            "orientationOnByDefault": true,
            "yaw" : -40,                     // default: 0
            "pitch": -10,                   // default: 0
            "hfov": computedHFOV,           // default: 100
            "hotSpots": hotspotData
        });
    </script>
</body>

</html>